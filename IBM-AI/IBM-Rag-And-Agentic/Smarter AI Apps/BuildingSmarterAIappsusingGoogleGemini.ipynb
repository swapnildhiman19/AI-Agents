{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ea3efde",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Google Gemini SDK + LangChain integration (replaces ibm-watsonx-ai + langchain-ibm)\n",
    "!pip install google-generativeai langchain-google-genai\n",
    "\n",
    "# LangChain core (same as original, these are provider-agnostic)\n",
    "!pip install langchain langchain-core langchain-community langchain-experimental langchainhub\n",
    "\n",
    "# PDF loading (same as original)\n",
    "!pip install pypdf\n",
    "\n",
    "# Vector database (same as original)\n",
    "!pip install chromadb\n",
    "\n",
    "# For loading .env file with your GOOGLE_API_KEY\n",
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5fd8d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# ============================================================\n",
    "# Remove corporate proxy settings that block Google API access\n",
    "# (Walmart VPN/proxy intercepts HTTPS calls to external APIs)\n",
    "# ============================================================\n",
    "for proxy_var in [\"HTTP_PROXY\", \"HTTPS_PROXY\", \"http_proxy\", \"https_proxy\"]:\n",
    "    os.environ.pop(proxy_var, None)\n",
    "\n",
    "# ============================================================\n",
    "# Load your Google Gemini API key from the .env file\n",
    "# The .env file is in the same folder as this notebook\n",
    "# with the line: GOOGLE_API_KEY=your_actual_key_here\n",
    "# Get a free key from: https://aistudio.google.com/apikey\n",
    "# ============================================================\n",
    "load_dotenv()  # Reads the .env file and loads vars into os.environ\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "if not GOOGLE_API_KEY or GOOGLE_API_KEY == \"YOUR_API_KEY_HERE\":\n",
    "    raise ValueError(\"Please set your GOOGLE_API_KEY in the .env file!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6b344ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warnings suppression -- stays exactly the same\n",
    "def warn(*args, **kwargs):\n",
    "    pass\n",
    "import warnings\n",
    "warnings.warn = warn\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['ANONYMIZED_TELEMETRY'] = 'False'\n",
    "\n",
    "# Google Gemini equivalents of the IBM imports\n",
    "import google.generativeai as genai                          # Replaces: ModelInference (direct API access)\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI    # Replaces: WatsonxLLM (LangChain wrapper)\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings  # For embeddings (you'll need this later for vector stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b7f8419",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load API key from your .env file\n",
    "load_dotenv()\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Configure the Gemini SDK\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# --- For direct Gemini SDK calls (equivalent of ModelInference) ---\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=\"gemini-2.0-flash\",\n",
    "    generation_config=genai.types.GenerationConfig(\n",
    "        max_output_tokens=256,    # was GenParams.MAX_NEW_TOKENS\n",
    "        temperature=0.2,          # was GenParams.TEMPERATURE\n",
    "    )\n",
    ")\n",
    "\n",
    "# --- For LangChain chains (equivalent of WatsonxLLM) ---\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    google_api_key=GOOGLE_API_KEY,\n",
    "    max_output_tokens=256,\n",
    "    temperature=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2a1b9b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mai ek AI assistant hu, isliye meri koi bhavna nahi hoti. Mai theek hu, aur aapki madad karne ke liye taiyar hu. Aap kaise hain?\n",
      "\n",
      "Mai ek AI assistant hu, isliye meri koi bhavna nahi hoti. Mai theek hu, aur aapki madad karne ke liye taiyar hu. Aap kaise hain?\n",
      "\n"
     ]
    }
   ],
   "source": [
    "msg = model.generate_content(\"Aap kaisi ho ma'am.\")\n",
    "print(msg.candidates[0].content.parts[0].text)\n",
    "print(msg.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "758aaa9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove corporate proxy settings that block Google API access\n",
    "for proxy_var in [\"HTTP_PROXY\", \"HTTPS_PROXY\", \"http_proxy\", \"https_proxy\"]:\n",
    "    os.environ.pop(proxy_var, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "602217ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am doing well, thank you for asking! As a large language model, I don't experience emotions or feelings in the same way humans do, but I am functioning optimally and ready to assist you with any questions or tasks you have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "print(llm.invoke(\"How are you ?\").content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8d071335",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0848a75d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Thank you for coming in today. Please, have a seat.\n",
      "\n",
      "I'm excited to learn more about you and your experience. As you know, we're a fast-growing startup in the AI space, and we're looking for a talented iOS Developer to join our team and help us build innovative and user-friendly mobile experiences.\n",
      "\n",
      "Before we dive into the technical questions, could you please tell me a little bit about yourself and what excites you about iOS development, particularly in the context of AI-driven applications?\n"
     ]
    }
   ],
   "source": [
    "msg = llm.invoke(\n",
    "    [\n",
    "        SystemMessage(content=\"You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\"),\n",
    "        HumanMessage(content=\"Hello ma'am.\")\n",
    "    ]\n",
    ")\n",
    "print(msg.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b7ab29c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! Thank you for coming in today. Please, have a seat.\n",
      "\n",
      "I'm excited to learn more about you and your experience. As you know, we're a fast-paced startup in the AI space, and we're looking for a passionate and skilled iOS Developer to join our team. We need someone who can not only build great apps but also understands the potential of integrating AI into the mobile experience.\n",
      "\n",
      "Before we dive into the technical questions, could you please walk me through your background and tell me a bit about what excites you about iOS development and AI?\n",
      "[SystemMessage(content='You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello ma'am.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello! Thank you for coming in today. Please, have a seat.\\n\\nI'm excited to learn more about you and your experience. As you know, we're a fast-paced startup in the AI space, and we're looking for a passionate and skilled iOS Developer to join our team. We need someone who can not only build great apps but also understands the potential of integrating AI into the mobile experience.\\n\\nBefore we dive into the technical questions, could you please walk me through your background and tell me a bit about what excites you about iOS development and AI?\", additional_kwargs={}, response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash', 'safety_ratings': [], 'model_provider': 'google_genai'}, id='lc_run--019c5ae6-adf1-7ec3-bf2d-f268f19b8b79-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 37, 'output_tokens': 119, 'total_tokens': 156, 'input_token_details': {'cache_read': 0}})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "conversationHistory = [\n",
    "    SystemMessage(content=\"You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\")\n",
    "]\n",
    "\n",
    "def chat_with_llm(user_input):\n",
    "    conversationHistory.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(conversationHistory)\n",
    "    conversationHistory.append(response)\n",
    "    return response.content\n",
    "\n",
    "print(chat_with_llm(\"Hello ma'am.\"))\n",
    "\n",
    "print(conversationHistory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993e3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "conversationHistory = [\n",
    "    SystemMessage(content=\"You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\")\n",
    "]\n",
    "\n",
    "def chat_with_llm(user_input):\n",
    "    conversationHistory.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(conversationHistory)\n",
    "    conversationHistory.append(response)\n",
    "    return response.content\n",
    "\n",
    "def display_chat():\n",
    "    \"\"\"Prints the full conversation history in a clean chat view\"\"\"\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"ðŸ“‹ CONVERSATION HISTORY\")\n",
    "    print(\"=\" * 60)\n",
    "    for msg in conversationHistory:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            print(f\"\\nðŸ”§ [SYSTEM]: {msg.content}\")\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            print(f\"\\nðŸ§‘ [YOU]: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"\\nðŸ¤– [AI]: {msg.content}\")\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "\n",
    "# Interactive loop -- type \"quit\" to exit\n",
    "while True:\n",
    "    user_input = input(\"\\nðŸ§‘ You: \")\n",
    "    if user_input.lower() in [\"quit\", \"exit\", \"bye\"]:\n",
    "        print(\"Ending interview. Goodbye!\")\n",
    "        display_chat()  # Show full history at the end\n",
    "        break\n",
    "    \n",
    "    response = chat_with_llm(user_input)\n",
    "    print(f\"\\nðŸ¤– AI: {response}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1c48a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "\n",
    "# Run this cell ONCE to initialize\n",
    "conversationHistory = [\n",
    "    SystemMessage(content=\"You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\")\n",
    "]\n",
    "\n",
    "def chat_with_llm(user_input):\n",
    "    conversationHistory.append(HumanMessage(content=user_input))\n",
    "    response = llm.invoke(conversationHistory)\n",
    "    conversationHistory.append(response)\n",
    "    return response.content\n",
    "\n",
    "def display_chat():\n",
    "    \"\"\"Prints the full conversation history in a clean chat view\"\"\"\n",
    "    print(\"=\" * 60)\n",
    "    for msg in conversationHistory:\n",
    "        if isinstance(msg, SystemMessage):\n",
    "            print(f\"\\nðŸ”§ [SYSTEM]: {msg.content}\")\n",
    "        elif isinstance(msg, HumanMessage):\n",
    "            print(f\"\\nðŸ§‘ [YOU]: {msg.content}\")\n",
    "        elif isinstance(msg, AIMessage):\n",
    "            print(f\"\\nðŸ¤– [AI]: {msg.content}\")\n",
    "    print(\"\\n\" + \"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "701e7b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¤– AI: Hello! Please, call me [My Name, if applicable, or just leave it as \"Hello\"]. Thank you for coming in today. I'm excited to learn more about you and your experience.\n",
      "\n",
      "This role is for an iOS Developer at [Startup Name], a fast-growing Indian startup leveraging AI to [briefly describe what the startup does]. We're looking for someone passionate about building innovative and user-friendly mobile experiences.\n",
      "\n",
      "To start, could you please walk me through your background and tell me a bit about your experience with iOS development?\n",
      "\n",
      "============================================================\n",
      "\n",
      "ðŸ”§ [SYSTEM]: You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\n",
      "\n",
      "ðŸ§‘ [YOU]: Hello ma'am.\n",
      "\n",
      "ðŸ§‘ [YOU]: Hello ma'am.\n",
      "\n",
      "ðŸ¤– [AI]: Hello! Please, call me [My Name, if applicable, or just leave it as \"Hello\"]. Thank you for coming in today. I'm excited to learn more about you and your experience.\n",
      "\n",
      "This role is for an iOS Developer at [Startup Name], a fast-growing Indian startup leveraging AI to [briefly describe what the startup does]. We're looking for someone passionate about building innovative and user-friendly mobile experiences.\n",
      "\n",
      "To start, could you please walk me through your background and tell me a bit about your experience with iOS development?\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Change this message and re-run this cell for each turn\n",
    "print(\"ðŸ¤– AI:\", chat_with_llm(\"Hello ma'am.\"))\n",
    "print()\n",
    "display_chat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "280e1d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9e929064",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\n",
    "    {user_input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "input_ = {\"user_input\": \"Hello ma'am.\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5672b3eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text=\"\\n    You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\\n    Hello ma'am.\\n    \")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke(input_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85ad9d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.', additional_kwargs={}, response_metadata={}), HumanMessage(content=\"Hello ma'am.\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Hello ma'am.\", additional_kwargs={}, response_metadata={}, tool_calls=[], invalid_tool_calls=[])])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant who plays a role of iOS interviewer who is hiring for iOS Developer in Indian Startup which is at par with on going trends of AI.\"),\n",
    "        (\"human\", \"{user_input}\"),\n",
    "        (\"ai\", \"Hello {user_input}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "prompt.invoke({\"user_input\": \"Hello ma'am.\"})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9313d75e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ibm-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
