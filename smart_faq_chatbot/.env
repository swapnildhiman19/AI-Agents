# Local LLM Server Configuration
LLM_BASE_URL=http://localhost:8080/v1/chat/completions
LLM_MODEL=Meta-Llama-3.1-8B-Instruct.Q8_0.llamafile
